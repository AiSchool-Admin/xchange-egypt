# ğŸ¤ Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„Ø°ÙƒÙŠ Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© - Arabic Voice Assistant
## Xchange AI Voice-Powered Shopping Assistant

**Ø§Ù„Ø£ÙˆÙ„ÙˆÙŠØ©:** â­ Ù…ØªÙˆØ³Ø·Ø© (Ù…ÙŠØ²Ø© ÙØ±ÙŠØ¯Ø©)
**Ø§Ù„ØªØ£Ø«ÙŠØ±:** +20% accessibility, +15% engagement
**ØµØ¹ÙˆØ¨Ø© Ø§Ù„ØªØ·ÙˆÙŠØ±:** Ø¹Ø§Ù„ÙŠØ©
**Ø§Ù„ÙˆÙ‚Øª Ø§Ù„Ù…Ù‚Ø¯Ø±:** 10-12 Ø£Ø³Ø¨ÙˆØ¹

---

## ğŸ“‹ Table of Contents

1. [Overview](#overview)
2. [Use Cases](#use-cases)
3. [Technical Architecture](#architecture)
4. [Voice Recognition (ASR)](#asr)
5. [Natural Language Understanding](#nlu)
6. [Text-to-Speech](#tts)
7. [Conversation Flow](#conversation)
8. [Implementation Guide](#implementation)
9. [Accessibility Features](#accessibility)

---

## 1. Overview {#overview}

### 1.1 Ø§Ù„Ù…Ø´ÙƒÙ„Ø©

**ØªØ­Ø¯ÙŠØ§Øª ØªØ¬Ø±Ø¨Ø© Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… Ø§Ù„Ø­Ø§Ù„ÙŠØ©:**

```
ğŸ“± 38% Ù…Ù† Ø§Ù„Ù…ØµØ±ÙŠÙŠÙ† ÙŠÙØ¶Ù„ÙˆÙ† Ø§Ù„ØµÙˆØª Ø¹Ù„Ù‰ Ø§Ù„ÙƒØªØ§Ø¨Ø©
ğŸ”¤ 25% ÙŠØ¬Ø¯ÙˆÙ† ØµØ¹ÙˆØ¨Ø© ÙÙŠ Ø§Ù„ÙƒØªØ§Ø¨Ø© Ø¨Ø§Ù„Ø¹Ø±Ø¨ÙŠØ© Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„
ğŸ‘ï¸ 15% ÙŠØ¹Ø§Ù†ÙˆÙ† Ù…Ù† ØµØ¹ÙˆØ¨Ø§Øª Ø¨ØµØ±ÙŠØ©
â±ï¸ Ø§Ù„Ø¨Ø­Ø« Ø§Ù„ÙƒØªØ§Ø¨ÙŠ ÙŠØ£Ø®Ø° ÙˆÙ‚Øª Ø£Ø·ÙˆÙ„ 3x Ù…Ù† Ø§Ù„ØµÙˆØªÙŠ
ğŸ“¶ Ø§Ù„ÙƒØªØ§Ø¨Ø© ØµØ¹Ø¨Ø© Ø£Ø«Ù†Ø§Ø¡ Ø§Ù„ØªÙ†Ù‚Ù„
```

### 1.2 Ø§Ù„Ø­Ù„

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚       Ø§Ù„Ù…Ø³Ø§Ø¹Ø¯ Ø§Ù„ØµÙˆØªÙŠ Ø§Ù„Ø°ÙƒÙŠ - Ø§Ù„Ù‚Ø¯Ø±Ø§Øª              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                       â”‚
â”‚  ğŸ¤ ÙÙ‡Ù… Ø§Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ©                             â”‚
â”‚     â€¢ ØªØ¹Ø±Ù Ø¹Ù„Ù‰ Ø§Ù„ÙƒÙ„Ø§Ù… Ø§Ù„Ù…ØµØ±ÙŠ Ø§Ù„Ø¹Ø§Ù…ÙŠ               â”‚
â”‚     â€¢ ÙÙ‡Ù… Ø§Ù„ØªØ¹Ø¨ÙŠØ±Ø§Øª Ø§Ù„Ù…Ø­Ù„ÙŠØ©                         â”‚
â”‚     â€¢ Ø¯Ø¹Ù… Ø§Ù„Ù„Ù‡Ø¬Ø§Øª Ø§Ù„Ø¥Ù‚Ù„ÙŠÙ…ÙŠØ©                         â”‚
â”‚                                                       â”‚
â”‚  ğŸ” Ø¨Ø­Ø« ØµÙˆØªÙŠ Ø°ÙƒÙŠ                                   â”‚
â”‚     â€¢ "Ø¯ÙˆØ± Ù„ÙŠ Ù…ÙˆØ¨Ø§ÙŠÙ„ Ø³Ø§Ù…Ø³ÙˆÙ†Ø¬ Ø±Ø®ÙŠØµ"                 â”‚
â”‚     â€¢ "Ø¹Ø§ÙŠØ² Ø¹Ø±Ø¨ÙŠØ© ØªÙˆÙŠÙˆØªØ§ Ù…ÙˆØ¯ÙŠÙ„ 2020"               â”‚
â”‚     â€¢ "ÙÙŠÙ‡ Ø°Ù‡Ø¨ Ø¹ÙŠØ§Ø± 21 ÙƒØ§Ù…ØŸ"                       â”‚
â”‚                                                       â”‚
â”‚  ğŸ’¬ Ù…Ø­Ø§Ø¯Ø«Ø© Ø·Ø¨ÙŠØ¹ÙŠØ©                                   â”‚
â”‚     â€¢ Ø£Ø³Ø¦Ù„Ø© Ù…ØªØ§Ø¨Ø¹Ø© Ø°ÙƒÙŠØ©                            â”‚
â”‚     â€¢ ÙÙ‡Ù… Ø§Ù„Ø³ÙŠØ§Ù‚                                    â”‚
â”‚     â€¢ Ø±Ø¯ÙˆØ¯ Ø·Ø¨ÙŠØ¹ÙŠØ© Ø¨Ø§Ù„ØµÙˆØª                           â”‚
â”‚                                                       â”‚
â”‚  ğŸ›’ Ø¥ØªÙ…Ø§Ù… Ø§Ù„Ø¹Ù…Ù„ÙŠØ§Øª Ø¨Ø§Ù„ØµÙˆØª                          â”‚
â”‚     â€¢ Ø¥Ø¶Ø§ÙØ© Ø¥Ø¹Ù„Ø§Ù† ÙƒØ§Ù…Ù„ Ø¨Ø§Ù„ØµÙˆØª                      â”‚
â”‚     â€¢ Ø§Ù„ØªÙØ§ÙˆØ¶ Ø§Ù„ØµÙˆØªÙŠ                                â”‚
â”‚     â€¢ ØªØ£ÙƒÙŠØ¯ Ø§Ù„Ø·Ù„Ø¨Ø§Øª                                 â”‚
â”‚                                                       â”‚
â”‚  â™¿ accessibility ÙƒØ§Ù…Ù„Ø©                             â”‚
â”‚     â€¢ Ù„Ù„Ù…ÙƒÙÙˆÙÙŠÙ† ÙˆØ¶Ø¹Ø§Ù Ø§Ù„Ø¨ØµØ±                        â”‚
â”‚     â€¢ Ù„Ù„Ø£Ù…ÙŠÙŠÙ†                                       â”‚
â”‚     â€¢ Ù„ÙƒØ¨Ø§Ø± Ø§Ù„Ø³Ù†                                    â”‚
â”‚                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## 2. Use Cases {#use-cases}

### 2.1 Ø§Ù„Ø¨Ø­Ø« Ø§Ù„ØµÙˆØªÙŠ

```
ğŸ‘¤ User: "ÙŠØ§ Ø³Ù„Ø§Ù…ØŒ Ø¯ÙˆØ± Ù„ÙŠ Ù…ÙˆØ¨Ø§ÙŠÙ„ Ø³Ø§Ù…Ø³ÙˆÙ†Ø¬ Ø£Ù‚Ù„ Ù…Ù† 5000 Ø¬Ù†ÙŠÙ‡"

ğŸ¤– Assistant: "Ø­Ø§Ø¶Ø±ØŒ Ù„Ù‚ÙŠØª Ù„Ùƒ 12 Ù…ÙˆØ¨Ø§ÙŠÙ„ Ø³Ø§Ù…Ø³ÙˆÙ†Ø¬ Ø£Ù‚Ù„ Ù…Ù† 5000 Ø¬Ù†ÙŠÙ‡.
              Ø£Ø­Ø³Ù† Ù†ØªÙŠØ¬Ø©: Samsung A54 Ø¨Ù€ 4,800 Ø¬Ù†ÙŠÙ‡ ÙÙŠ Ø§Ù„Ø¬ÙŠØ²Ø©.
              Ø¹Ø§ÙŠØ² ØªØ´ÙˆÙ Ø§Ù„Ø¨Ø§Ù‚ÙŠØŸ"

ğŸ‘¤ User: "Ø¢Ù‡ Ø£Ø±ÙŠÙ†ÙŠ Ø§Ù„Ø¨Ø§Ù‚ÙŠ"

ğŸ¤– Assistant: "ØªÙ…Ø§Ù…ØŒ Ù‡Ø¹Ø±Ø¶Ù‡Ù… Ù„Ùƒ Ø¯Ù„ÙˆÙ‚ØªÙŠ..."
              [ÙŠØ¹Ø±Ø¶ Ø§Ù„Ù‚Ø§Ø¦Ù…Ø©]
```

### 2.2 Ø¥Ø¶Ø§ÙØ© Ø¥Ø¹Ù„Ø§Ù† Ø¨Ø§Ù„ØµÙˆØª

```
ğŸ‘¤ User: "Ø¹Ø§ÙŠØ² Ø£Ø¨ÙŠØ¹ Ù…ÙˆØ¨Ø§ÙŠÙ„ÙŠ"

ğŸ¤– Assistant: "ØªÙ…Ø§Ù…! Ø£ÙŠÙ‡ Ù†ÙˆØ¹ Ø§Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„ØŸ"

ğŸ‘¤ User: "Ø¢ÙŠÙÙˆÙ† 14 Ø¨Ø±Ùˆ"

ğŸ¤– Assistant: "Ù…Ù…ØªØ§Ø². ÙƒØ§Ù… Ø¬ÙŠØ¬Ø§ Ø§Ù„Ø°Ø§ÙƒØ±Ø©ØŸ"

ğŸ‘¤ User: "256"

ğŸ¤– Assistant: "ØªÙ…Ø§Ù…. Ø­Ø§Ù„ØªÙ‡ Ø¥ÙŠÙ‡ØŸ"

ğŸ‘¤ User: "Ø²ÙŠ Ø§Ù„Ø¬Ø¯ÙŠØ¯ØŒ Ø§Ø³ØªØ¹Ù…Ø§Ù„ Ø®ÙÙŠÙ"

ğŸ¤– Assistant: "Ø­Ù„Ùˆ. Ø¹Ø§ÙŠØ² ØªØ¨ÙŠØ¹Ù‡ Ø¨ÙƒØ§Ù…ØŸ"

ğŸ‘¤ User: "30 Ø£Ù„Ù"

ğŸ¤– Assistant: "Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙˆÙ‚ØŒ Ø§Ù„Ø³Ø¹Ø± Ø¯Ù‡ ÙƒÙˆÙŠØ³ Ø¬Ø¯Ø§Ù‹.
              Ù…Ø¹Ø§Ùƒ Ø§Ù„Ø¹Ù„Ø¨Ø© ÙˆØ§Ù„Ø´Ø§Ø­Ù†ØŸ"

ğŸ‘¤ User: "Ø¢Ù‡ Ù…Ø¹Ø§ÙŠØ§ ÙƒÙ„ Ø­Ø§Ø¬Ø©"

ğŸ¤– Assistant: "Ù…Ù…ØªØ§Ø²! Ù‡Ø§Ø®Ø¯ Ù…Ù†Ùƒ ÙƒØ§Ù… ØµÙˆØ±Ø© Ù„Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„ ÙˆÙ†Ø®Ù„Øµ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†ØŸ"
```

### 2.3 Ø§Ù„ØªÙØ§ÙˆØ¶ Ø§Ù„ØµÙˆØªÙŠ

```
ğŸ‘¤ Buyer: "Ø§ØªØµÙ„ Ø¨Ø§Ù„Ø¨Ø§Ø¦Ø¹"

ğŸ¤– Assistant: "Ø­Ø§Ø¶Ø±ØŒ Ù‡ÙˆØµÙ„Ùƒ Ø¨Ø§Ù„Ø¨Ø§Ø¦Ø¹ Ø¯Ù„ÙˆÙ‚ØªÙŠ...
              [ÙŠØªØµÙ„]
              Ø§Ù„Ø¨Ø§Ø¦Ø¹ Ù…Ø¹Ø§Ùƒ Ø¹Ù„Ù‰ Ø§Ù„Ø®Ø·"

ğŸ‘¤ Buyer: "Ø§Ù„Ø³Ù„Ø§Ù… Ø¹Ù„ÙŠÙƒÙ…ØŒ Ø§Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„ Ù„Ø³Ù‡ Ù…ÙˆØ¬ÙˆØ¯ØŸ"

ğŸ‘¤ Seller: "Ø£ÙŠÙˆÙ‡ Ù…ÙˆØ¬ÙˆØ¯"

ğŸ‘¤ Buyer: "Ù…Ù…ÙƒÙ† ØªÙ†Ø²Ù„ Ø§Ù„Ø³ï¿½ï¿½Ø± Ø´ÙˆÙŠØ©ØŸ"

ğŸ¤– Assistant [ÙŠØªØ¯Ø®Ù„]: "Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰ Ø§Ù„Ø³ÙˆÙ‚ØŒ Ø§Ù„Ø³Ø¹Ø± Ø§Ù„Ø­Ø§Ù„ÙŠ 9000 Ø¬.Ù…
                        Ø¹Ø§Ø¯Ù„ Ø¬Ø¯Ø§Ù‹. Ø§Ù„Ù…Ø´ØªØ±ÙŠ Ù…Ù…ÙƒÙ† ÙŠØ¹Ø±Ø¶ 8500 Ø¬.Ù…
                        ÙˆØ§Ù„Ø¨Ø§Ø¦Ø¹ ÙŠÙ‚Ø¨Ù„. Ø±Ø£ÙŠÙƒÙˆØ§ Ø¥ÙŠÙ‡ØŸ"
```

### 2.4 Ø§Ù„Ø§Ø³ØªÙØ³Ø§Ø±Ø§Øª ÙˆØ§Ù„Ø¯Ø¹Ù…

```
ğŸ‘¤ User: "Ø¥Ø²Ø§ÙŠ Ø£Ø¶ÙŠÙ Ø¥Ø¹Ù„Ø§Ù†ØŸ"

ğŸ¤– Assistant: "Ø³Ù‡Ù„Ø©! Ø§Ø¶ØºØ· Ø¹Ù„Ù‰ Ø²Ø± '+' ØªØ­ØªØŒ
              Ø£Ùˆ Ù‚ÙˆÙ„ Ù„ÙŠ 'Ø¹Ø§ÙŠØ² Ø£Ø¨ÙŠØ¹' ÙˆØ£Ù†Ø§ Ù‡Ø³Ø§Ø¹Ø¯Ùƒ Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©"

ğŸ‘¤ User: "Ø·ÙŠØ¨ Ø¥Ø²Ø§ÙŠ Ø£Ø¹Ø±Ù Ø§Ù„Ø¥Ø¹Ù„Ø§Ù† Ø¨ØªØ§Ø¹ÙŠ Ø¸Ù‡Ø±ØŸ"

ğŸ¤– Assistant: "ØªÙ‚Ø¯Ø± ØªØ´ÙˆÙÙ‡ ÙÙŠ 'Ø¥Ø¹Ù„Ø§Ù†Ø§ØªÙŠ' Ù…Ù† Ø§Ù„Ù‚Ø§Ø¦Ù…Ø© Ø§Ù„Ø±Ø¦ÙŠØ³ÙŠØ©ØŒ
              Ø£Ùˆ Ù‚ÙˆÙ„ Ù„ÙŠ 'ÙˆØ±Ù‘Ù†ÙŠ Ø¥Ø¹Ù„Ø§Ù†Ø§ØªÙŠ' ÙˆØ£Ù†Ø§ Ù‡ÙØªØ­Ù‡Ø§Ù„Ùƒ"
```

---

## 3. Technical Architecture {#architecture}

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚              VOICE ASSISTANT PIPELINE                 â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                       â”‚
â”‚  ğŸ¤ User speaks in Arabic                           â”‚
â”‚         â”‚                                             â”‚
â”‚         â–¼                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚
â”‚  â”‚  Audio Capture       â”‚                            â”‚
â”‚  â”‚  â€¢ React Native      â”‚                            â”‚
â”‚  â”‚  â€¢ 16kHz, Mono       â”‚                            â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                            â”‚
â”‚            â”‚                                          â”‚
â”‚            â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                        â”‚
â”‚  â”‚  Speech-to-Text (ASR)    â”‚                        â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                        â”‚
â”‚  â”‚  â”‚ Primary: Whisper   â”‚  â”‚                        â”‚
â”‚  â”‚  â”‚ (OpenAI)           â”‚  â”‚                        â”‚
â”‚  â”‚  â”‚ Accuracy: 96%      â”‚  â”‚                        â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                        â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                        â”‚
â”‚  â”‚  â”‚ Fallback: Xina AI  â”‚  â”‚                        â”‚
â”‚  â”‚  â”‚ (Egyptian dialect) â”‚  â”‚                        â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                        â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                        â”‚
â”‚            â”‚                                          â”‚
â”‚            â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚  NLU (Understanding)         â”‚                    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                    â”‚
â”‚  â”‚  â”‚ Intent Detection       â”‚  â”‚                    â”‚
â”‚  â”‚  â”‚ (GPT-4)                â”‚  â”‚                    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                    â”‚
â”‚  â”‚  â”‚ Entity Extraction      â”‚  â”‚                    â”‚
â”‚  â”‚  â”‚ (brand, price, etc.)   â”‚  â”‚                    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚            â”‚                                          â”‚
â”‚            â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚  Action Handler              â”‚                    â”‚
â”‚  â”‚  â€¢ Search products           â”‚                    â”‚
â”‚  â”‚  â€¢ Create listing            â”‚                    â”‚
â”‚  â”‚  â€¢ Start negotiation         â”‚                    â”‚
â”‚  â”‚  â€¢ Answer questions          â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚            â”‚                                          â”‚
â”‚            â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚  Response Generation         â”‚                    â”‚
â”‚  â”‚  (GPT-4 + Context)           â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚            â”‚                                          â”‚
â”‚            â–¼                                          â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                    â”‚
â”‚  â”‚  Text-to-Speech (TTS)        â”‚                    â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚                    â”‚
â”‚  â”‚  â”‚ ElevenLabs             â”‚  â”‚                    â”‚
â”‚  â”‚  â”‚ (Arabic voice)         â”‚  â”‚                    â”‚
â”‚  â”‚  â”‚ Natural, expressive    â”‚  â”‚                    â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚                    â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                    â”‚
â”‚            â”‚                                          â”‚
â”‚            â–¼                                          â”‚
â”‚  ğŸ”Š User hears response                              â”‚
â”‚                                                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Technology Stack

| Component | Technology | Purpose |
|-----------|------------|---------|
| **ASR** | OpenAI Whisper v3 | Arabic speech recognition |
| **ASR Fallback** | Xina AI | Egyptian dialect specialist |
| **NLU** | GPT-4 Turbo | Intent & entity extraction |
| **TTS** | ElevenLabs Multilingual | Natural Arabic voice |
| **TTS Fallback** | Google Cloud TTS | Backup voice |
| **Audio** | React Native Voice | Mobile mic access |
| **Streaming** | WebSockets | Real-time communication |
| **Cache** | Redis | Session & context storage |

---

## 4. Voice Recognition (ASR) {#asr}

### 4.1 Whisper Integration

```typescript
// services/speech-recognition.service.ts

import OpenAI from 'openai';
import fs from 'fs';

const openai = new OpenAI({
  apiKey: process.env.OPENAI_API_KEY
});

export class SpeechRecognitionService {

  /**
   * ØªØ­ÙˆÙŠÙ„ Ø§Ù„ØµÙˆØª Ù„Ù†Øµ Ø¨Ø§Ø³ØªØ®Ø¯Ø§Ù… Whisper
   */
  async transcribe(audioFilePath: string): Promise<{
    text: string;
    language: string;
    confidence: number;
  }> {

    try {
      const transcription = await openai.audio.transcriptions.create({
        file: fs.createReadStream(audioFilePath),
        model: 'whisper-1',
        language: 'ar',  // Arabic
        response_format: 'verbose_json',
        temperature: 0.2  // Ù„Ù„Ø¯Ù‚Ø©
      });

      return {
        text: transcription.text,
        language: transcription.language || 'ar',
        confidence: this.estimateConfidence(transcription)
      };

    } catch (error) {
      console.error('Whisper transcription failed:', error);

      // Fallback to Xina AI
      return this.transcribeWithXina(audioFilePath);
    }
  }

  /**
   * Fallback: Xina AI Ù„Ù„Ù‡Ø¬Ø© Ø§Ù„Ù…ØµØ±ÙŠØ©
   */
  private async transcribeWithXina(audioFilePath: string): Promise<any> {
    // TODO: Integrate Xina AI API
    // https://xina.ai/

    const xinaApiUrl = process.env.XINA_API_URL;
    const apiKey = process.env.XINA_API_KEY;

    const formData = new FormData();
    formData.append('audio', fs.createReadStream(audioFilePath));
    formData.append('dialect', 'egyptian');

    const response = await fetch(xinaApiUrl!, {
      method: 'POST',
      headers: {
        'Authorization': `Bearer ${apiKey}`
      },
      body: formData
    });

    const result = await response.json();

    return {
      text: result.transcript,
      language: 'ar-EG',
      confidence: result.confidence
    };
  }

  /**
   * ØªÙ‚Ø¯ÙŠØ± Ù…Ø³ØªÙˆÙ‰ Ø§Ù„Ø«Ù‚Ø© Ù…Ù† Ø§Ù„Ù†Øµ
   */
  private estimateConfidence(transcription: any): number {
    // Whisper Ù„Ø§ ÙŠØ¹Ø·ÙŠ confidence score Ù…Ø¨Ø§Ø´Ø±Ø©
    // Ù†Ù‚Ø¯Ø±Ù‡ Ø¨Ù†Ø§Ø¡Ù‹ Ø¹Ù„Ù‰:

    const text = transcription.text;

    let confidence = 100;

    // Ø®ØµÙ… Ù„Ù„Ù†ØµÙˆØµ Ø§Ù„Ù‚ØµÙŠØ±Ø© Ø¬Ø¯Ø§Ù‹
    if (text.length < 10) {
      confidence -= 20;
    }

    // Ø®ØµÙ… Ù„Ù„Ø±Ù…ÙˆØ² Ø§Ù„ØºØ±ÙŠØ¨Ø©
    const weirdChars = (text.match(/[^\u0600-\u06FF\s\d]/g) || []).length;
    confidence -= weirdChars * 5;

    // Ø®ØµÙ… Ù„Ù„ÙƒÙ„Ù…Ø§Øª ØºÙŠØ± Ø§Ù„Ù…ÙÙ‡ÙˆÙ…Ø©
    const arabicWords = text.split(/\s+/).filter(w => /[\u0600-\u06FF]/.test(w));
    if (arabicWords.length < 2) {
      confidence -= 30;
    }

    return Math.max(0, Math.min(100, confidence));
  }
}
```

### 4.2 Real-time Streaming

```typescript
// services/streaming-asr.service.ts

import { WebSocket } from 'ws';

export class StreamingASRService {

  private ws: WebSocket | null = null;
  private audioBuffer: Buffer[] = [];

  /**
   * Ø¨Ø¯Ø¡ Ø¬Ù„Ø³Ø© ØªØ¹Ø±Ù ØµÙˆØªÙŠ Ù…Ø³ØªÙ…Ø±
   */
  async startStream(
    onTranscript: (text: string, isFinal: boolean) => void
  ): Promise<void> {

    this.ws = new WebSocket(process.env.WHISPER_STREAMING_URL!);

    this.ws.on('open', () => {
      console.log('Streaming ASR connected');

      // Ø¥Ø±Ø³Ø§Ù„ Ø¥Ø¹Ø¯Ø§Ø¯Ø§Øª
      this.ws!.send(JSON.stringify({
        type: 'config',
        language: 'ar',
        sampleRate: 16000,
        interim_results: true
      }));
    });

    this.ws.on('message', (data) => {
      const result = JSON.parse(data.toString());

      if (result.type === 'transcript') {
        onTranscript(result.text, result.is_final);
      }
    });

    this.ws.on('error', (error) => {
      console.error('Streaming ASR error:', error);
    });
  }

  /**
   * Ø¥Ø±Ø³Ø§Ù„ audio chunk
   */
  sendAudioChunk(audioChunk: Buffer): void {
    if (this.ws && this.ws.readyState === WebSocket.OPEN) {
      this.ws.send(audioChunk);
    } else {
      this.audioBuffer.push(audioChunk);
    }
  }

  /**
   * Ø¥Ù†Ù‡Ø§Ø¡ Ø§Ù„Ø¬Ù„Ø³Ø©
   */
  stopStream(): void {
    if (this.ws) {
      this.ws.close();
      this.ws = null;
    }
    this.audioBuffer = [];
  }
}
```

---

## 5. Natural Language Understanding {#nlu}

### 5.1 Intent Detection

```typescript
// services/nlu.service.ts

import OpenAI from 'openai';

const openai = new OpenAI();

export enum Intent {
  SEARCH_PRODUCT = 'search_product',
  CREATE_LISTING = 'create_listing',
  NEGOTIATE = 'negotiate',
  ASK_QUESTION = 'ask_question',
  NAVIGATE = 'navigate',
  CANCEL = 'cancel',
  CONFIRM = 'confirm',
  UNKNOWN = 'unknown'
}

export class NLUService {

  /**
   * Ø§Ø³ØªØ®Ø±Ø§Ø¬ Intent ÙˆØ§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…Ù† Ø§Ù„Ù†Øµ
   */
  async understand(text: string, context?: ConversationContext): Promise<{
    intent: Intent;
    entities: Record<string, any>;
    confidence: number;
  }> {

    const systemPrompt = `
Ø£Ù†Øª Ù†Ø¸Ø§Ù… ÙÙ‡Ù… Ù„ØºØ© Ø·Ø¨ÙŠØ¹ÙŠØ© Ù„Ù…Ù†ØµØ© Xchange Ø§Ù„Ù…ØµØ±ÙŠØ©.
Ù…Ù‡Ù…ØªÙƒ ØªØ­Ù„ÙŠÙ„ ÙƒÙ„Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù… ÙˆØªØ­Ø¯ÙŠØ¯:
1. Intent (Ø§Ù„Ù†ÙŠØ©)
2. Entities (Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ø§Ù„Ù…Ù‡Ù…Ø©)

Ø§Ù„Ù€ Intents Ø§Ù„Ù…ØªØ§Ø­Ø©:
- search_product: Ø§Ù„Ø¨Ø­Ø« Ø¹Ù† Ù…Ù†ØªØ¬
- create_listing: Ø¥Ø¶Ø§ÙØ© Ø¥Ø¹Ù„Ø§Ù†
- negotiate: Ø§Ù„ØªÙØ§ÙˆØ¶ Ø¹Ù„Ù‰ Ø§Ù„Ø³Ø¹Ø±
- ask_question: Ø³Ø¤Ø§Ù„ Ø¹Ø§Ù…
- navigate: Ø§Ù„ØªÙ†Ù‚Ù„ ÙÙŠ Ø§Ù„ØªØ·Ø¨ÙŠÙ‚
- confirm: ØªØ£ÙƒÙŠØ¯
- cancel: Ø¥Ù„ØºØ§Ø¡

Ø±Ø¯ Ø¨Ù€ JSON ÙÙ‚Ø·:
{
  "intent": "...",
  "entities": {...},
  "confidence": 0-100
}
    `.trim();

    const userPrompt = `
${context ? `Ø§Ù„Ø³ÙŠØ§Ù‚ Ø§Ù„Ø³Ø§Ø¨Ù‚: ${JSON.stringify(context)}` : ''}

ÙƒÙ„Ø§Ù… Ø§Ù„Ù…Ø³ØªØ®Ø¯Ù…: "${text}"

Ø­Ù„Ù„ ÙˆØ§Ø³ØªØ®Ø±Ø¬ Ø§Ù„Ù€ intent ÙˆØ§Ù„Ù€ entities.
    `.trim();

    const response = await openai.chat.completions.create({
      model: 'gpt-4-turbo-preview',
      messages: [
        { role: 'system', content: systemPrompt },
        { role: 'user', content: userPrompt }
      ],
      response_format: { type: 'json_object' },
      temperature: 0.3
    });

    const result = JSON.parse(response.choices[0].message.content || '{}');

    return {
      intent: result.intent as Intent,
      entities: result.entities || {},
      confidence: result.confidence || 80
    };
  }

  /**
   * Ø§Ø³ØªØ®Ø±Ø§Ø¬ entities Ù…Ø­Ø¯Ø¯Ø©
   */
  extractEntities(text: string): {
    brand?: string;
    model?: string;
    price?: number;
    priceRange?: { min: number; max: number };
    category?: string;
    condition?: string;
    location?: string;
  } {

    const entities: any = {};

    // Brand extraction
    const brands = ['Ø³Ø§Ù…Ø³ÙˆÙ†Ø¬', 'Ø¢ÙŠÙÙˆÙ†', 'ØªÙˆÙŠÙˆØªØ§', 'Ù‡ÙˆÙ†Ø¯Ø§', 'Ø°Ù‡Ø¨', 'ÙØ¶Ø©'];
    for (const brand of brands) {
      if (text.includes(brand)) {
        entities.brand = brand;
        break;
      }
    }

    // Price extraction
    const priceMatch = text.match(/(\d+)\s*(Ø£Ù„Ù|Ø¢Ù„Ø§Ù|Ø¬Ù†ÙŠÙ‡)/);
    if (priceMatch) {
      let price = parseInt(priceMatch[1]);
      if (priceMatch[2] === 'Ø£Ù„Ù' || priceMatch[2] === 'Ø¢Ù„Ø§Ù') {
        price *= 1000;
      }
      entities.price = price;
    }

    // Price range
    const rangeMatch = text.match(/Ù…Ù†\s*(\d+)\s*Ù„Ù€?\s*(\d+)/);
    if (rangeMatch) {
      entities.priceRange = {
        min: parseInt(rangeMatch[1]) * 1000,
        max: parseInt(rangeMatch[2]) * 1000
      };
    }

    // Location
    const governorates = ['Ø§Ù„Ù‚Ø§Ù‡Ø±Ø©', 'Ø§Ù„Ø¬ÙŠØ²Ø©', 'Ø§Ù„Ø¥Ø³ÙƒÙ†Ø¯Ø±ÙŠØ©', 'Ø§Ù„Ø´Ø±Ù‚ÙŠØ©'];
    for (const gov of governorates) {
      if (text.includes(gov)) {
        entities.location = gov;
        break;
      }
    }

    return entities;
  }
}
```

---

## 6. Text-to-Speech {#tts}

### 6.1 ElevenLabs Integration

```typescript
// services/text-to-speech.service.ts

import axios from 'axios';
import fs from 'fs';

export class TextToSpeechService {

  private apiKey: string;
  private voiceId: string;  // Arabic voice

  constructor() {
    this.apiKey = process.env.ELEVENLABS_API_KEY!;
    this.voiceId = process.env.ELEVENLABS_VOICE_ID!; // Arabic male/female
  }

  /**
   * ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ù„ØµÙˆØª
   */
  async synthesize(
    text: string,
    options?: {
      voice?: 'male' | 'female';
      speed?: number;
      emotion?: 'neutral' | 'friendly' | 'professional';
    }
  ): Promise<Buffer> {

    const voiceSettings = {
      stability: 0.75,
      similarity_boost: 0.75,
      style: 0.5,
      use_speaker_boost: true
    };

    try {
      const response = await axios.post(
        `https://api.elevenlabs.io/v1/text-to-speech/${this.voiceId}`,
        {
          text: text,
          model_id: 'eleven_multilingual_v2',
          voice_settings: voiceSettings
        },
        {
          headers: {
            'Accept': 'audio/mpeg',
            'xi-api-key': this.apiKey,
            'Content-Type': 'application/json'
          },
          responseType: 'arraybuffer'
        }
      );

      return Buffer.from(response.data);

    } catch (error) {
      console.error('ElevenLabs TTS failed:', error);

      // Fallback to Google TTS
      return this.synthesizeWithGoogle(text);
    }
  }

  /**
   * Fallback: Google Cloud TTS
   */
  private async synthesizeWithGoogle(text: string): Promise<Buffer> {
    const textToSpeech = require('@google-cloud/text-to-speech');
    const client = new textToSpeech.TextToSpeechClient();

    const request = {
      input: { text: text },
      voice: {
        languageCode: 'ar-XA',
        name: 'ar-XA-Wavenet-A',  // Male voice
        ssmlGender: 'MALE'
      },
      audioConfig: {
        audioEncoding: 'MP3',
        speakingRate: 1.0,
        pitch: 0.0
      }
    };

    const [response] = await client.synthesizeSpeech(request);
    return Buffer.from(response.audioContent as Uint8Array);
  }

  /**
   * ØªØ´ØºÙŠÙ„ Ø§Ù„ØµÙˆØª Ù…Ø¨Ø§Ø´Ø±Ø© Ø¹Ù„Ù‰ Ø§Ù„Ù…ÙˆØ¨Ø§ÙŠÙ„
   */
  async speak(text: string): Promise<string> {
    const audioBuffer = await this.synthesize(text);

    // Ø­ÙØ¸ Ù…Ø¤Ù‚Øª
    const tempPath = `/tmp/tts-${Date.now()}.mp3`;
    fs.writeFileSync(tempPath, audioBuffer);

    // Ø±ÙØ¹ Ù„Ù€ CDN
    const audioUrl = await this.uploadToCDN(tempPath);

    return audioUrl;
  }

  private async uploadToCDN(filePath: string): Promise<string> {
    // TODO: Upload to S3/CloudFront
    return 'https://cdn.xchange.com/audio/...';
  }
}
```

---

## 7. Conversation Flow {#conversation}

### 7.1 Conversation Manager

```typescript
// services/conversation.service.ts

export interface ConversationContext {
  sessionId: string;
  userId: string;
  currentIntent?: Intent;
  currentStep?: string;
  collectedData: Record<string, any>;
  history: Message[];
}

export class ConversationService {

  /**
   * Ù…Ø¹Ø§Ù„Ø¬Ø© Ø±Ø³Ø§Ù„Ø© ØµÙˆØªÙŠØ©
   */
  async handleVoiceMessage(
    audio: Buffer,
    context: ConversationContext
  ): Promise<{
    responseText: string;
    responseAudio: string;
    action?: string;
    data?: any;
  }> {

    // 1. Speech to Text
    const asr = new SpeechRecognitionService();
    const { text, confidence } = await asr.transcribe(audio);

    if (confidence < 60) {
      return {
        responseText: 'Ù…Ø¹Ù„Ø´ØŒ Ù…Ø³Ù…Ø¹ØªØ´ ÙƒÙˆÙŠØ³. Ù…Ù…ÙƒÙ† ØªØ¹ÙŠØ¯ ØªØ§Ù†ÙŠØŸ',
        responseAudio: await this.textToSpeech('Ù…Ø¹Ù„Ø´ØŒ Ù…Ø³Ù…Ø¹ØªØ´ ÙƒÙˆÙŠØ³. Ù…Ù…ÙƒÙ† ØªØ¹ÙŠØ¯ ØªØ§Ù†ÙŠØŸ')
      };
    }

    // 2. Understand Intent
    const nlu = new NLUService();
    const { intent, entities } = await nlu.understand(text, context);

    // 3. Update Context
    context.currentIntent = intent;
    context.collectedData = { ...context.collectedData, ...entities };
    context.history.push({
      role: 'user',
      content: text,
      timestamp: new Date()
    });

    // 4. Handle Intent
    const response = await this.handleIntent(intent, entities, context);

    // 5. Text to Speech
    const audioUrl = await this.textToSpeech(response.text);

    // 6. Save to history
    context.history.push({
      role: 'assistant',
      content: response.text,
      timestamp: new Date()
    });

    return {
      responseText: response.text,
      responseAudio: audioUrl,
      action: response.action,
      data: response.data
    };
  }

  /**
   * Ù…Ø¹Ø§Ù„Ø¬Ø© Intent
   */
  private async handleIntent(
    intent: Intent,
    entities: any,
    context: ConversationContext
  ): Promise<{ text: string; action?: string; data?: any }> {

    switch (intent) {

      case Intent.SEARCH_PRODUCT:
        return this.handleSearch(entities, context);

      case Intent.CREATE_LISTING:
        return this.handleCreateListing(entities, context);

      case Intent.NEGOTIATE:
        return this.handleNegotiate(entities, context);

      case Intent.ASK_QUESTION:
        return this.handleQuestion(entities, context);

      default:
        return {
          text: 'Ù…Ø¹Ù„Ø´ØŒ Ù…ÙÙ‡Ù…ØªØ´. Ù…Ù…ÙƒÙ† ØªÙˆØ¶Ø­ Ø£ÙƒØªØ±ØŸ'
        };
    }
  }

  /**
   * Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø§Ù„Ø¨Ø­Ø«
   */
  private async handleSearch(
    entities: any,
    context: ConversationContext
  ): Promise<any> {

    // Ø¨Ù†Ø§Ø¡ query Ø§Ù„Ø¨Ø­Ø«
    const query: any = {};

    if (entities.brand) query.brand = entities.brand;
    if (entities.category) query.category = entities.category;
    if (entities.priceRange) {
      query.price = {
        gte: entities.priceRange.min,
        lte: entities.priceRange.max
      };
    }
    if (entities.location) query.governorate = entities.location;

    // Ø§Ù„Ø¨Ø­Ø«
    const results = await prisma.listing.findMany({
      where: query,
      take: 10,
      orderBy: { createdAt: 'desc' }
    });

    if (results.length === 0) {
      return {
        text: 'Ù„Ù„Ø£Ø³Ù Ù…ÙÙŠØ´ Ù†ØªØ§Ø¦Ø¬. Ø¹Ø§ÙŠØ² ØªØ¬Ø±Ø¨ Ø¨Ø­Ø« ØªØ§Ù†ÙŠØŸ'
      };
    }

    const topResult = results[0];

    const response = `
Ù„Ù‚ÙŠØª Ù„Ùƒ ${results.length} Ù†ØªÙŠØ¬Ø©.
Ø£Ø­Ø³Ù† Ø¹Ø±Ø¶: ${topResult.title} Ø¨Ù€ ${topResult.price.toLocaleString()} Ø¬Ù†ÙŠÙ‡
ÙÙŠ ${topResult.governorate}.
Ø¹Ø§ÙŠØ² ØªØ´ÙˆÙ Ø§Ù„ØªÙØ§ØµÙŠÙ„ØŸ
    `.trim();

    return {
      text: response,
      action: 'show_search_results',
      data: { results }
    };
  }

  /**
   * Ø§Ù„ØªØ¹Ø§Ù…Ù„ Ù…Ø¹ Ø¥Ø¶Ø§ÙØ© Ø¥Ø¹Ù„Ø§Ù†
   */
  private async handleCreateListing(
    entities: any,
    context: ConversationContext
  ): Promise<any> {

    // Multi-turn conversation Ù„Ø¬Ù…Ø¹ ÙƒÙ„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª
    const collected = context.collectedData;

    // ØªØ­Ø¯ÙŠØ¯ Ø§Ù„Ø®Ø·ÙˆØ© Ø§Ù„Ø­Ø§Ù„ÙŠØ©
    if (!collected.category) {
      return {
        text: 'ØªÙ…Ø§Ù…! Ø£ÙŠÙ‡ Ù†ÙˆØ¹ Ø§Ù„Ù…Ù†ØªØ¬ Ø§Ù„Ù„ÙŠ Ø¹Ø§ÙŠØ² ØªØ¨ÙŠØ¹Ù‡ØŸ (Ù…ÙˆØ¨Ø§ÙŠÙ„ØŒ Ø¹Ø±Ø¨ÙŠØ©ØŒ Ø°Ù‡Ø¨ØŒ Ø¥Ù„Ø®)',
        action: 'await_category'
      };
    }

    if (!collected.brand) {
      return {
        text: `ØªÙ…Ø§Ù…. Ø£ÙŠÙ‡ Ø§Ù„Ù…Ø§Ø±ÙƒØ©ØŸ`,
        action: 'await_brand'
      };
    }

    if (!collected.price) {
      return {
        text: `Ø¹Ø§ÙŠØ² ØªØ¨ÙŠØ¹Ù‡ Ø¨ÙƒØ§Ù…ØŸ`,
        action: 'await_price'
      };
    }

    if (!collected.condition) {
      return {
        text: `Ø­Ø§Ù„ØªÙ‡ Ø¥ÙŠÙ‡ØŸ (Ø¬Ø¯ÙŠØ¯ØŒ Ù…Ù…ØªØ§Ø²ØŒ Ø¬ÙŠØ¯ØŒ Ù…Ù‚Ø¨ÙˆÙ„)`,
        action: 'await_condition'
      };
    }

    // ÙƒÙ„ Ø§Ù„Ù…Ø¹Ù„ÙˆÙ…Ø§Øª Ù…ØªÙˆÙØ±Ø© - Ø¥Ù†Ø´Ø§Ø¡ Ø§Ù„Ø¥Ø¹Ù„Ø§Ù†
    const listing = await prisma.listing.create({
      data: {
        userId: context.userId,
        category: collected.category,
        brand: collected.brand,
        price: collected.price,
        condition: collected.condition,
        title: `${collected.brand} ${collected.model || ''}`,
        status: 'draft'
      }
    });

    return {
      text: `ØªÙ…Ø§Ù… Ø®Ù„Ø§Øµ! Ø§Ù„Ø¥Ø¹Ù„Ø§Ù† Ø§ØªØ¹Ù…Ù„. Ø¯Ù„ÙˆÙ‚ØªÙŠ Ù‡Ø§Ø®Ø¯ Ù…Ù†Ùƒ ÙƒØ§Ù… ØµÙˆØ±Ø© Ù„Ù„Ù…Ù†ØªØ¬ Ø¹Ø´Ø§Ù† Ù†Ø®Ù„Øµ`,
      action: 'request_photos',
      data: { listingId: listing.id }
    };
  }

  /**
   * ØªØ­ÙˆÙŠÙ„ Ø§Ù„Ù†Øµ Ù„ØµÙˆØª
   */
  private async textToSpeech(text: string): Promise<string> {
    const tts = new TextToSpeechService();
    return tts.speak(text);
  }
}
```

---

## 8. Implementation Guide {#implementation}

### Phase 1: Basic Voice Recognition (Week 1-3)
```bash
- Whisper integration
- Basic Arabic ASR
- Simple command recognition
```

### Phase 2: NLU & Conversation (Week 4-6)
```bash
- GPT-4 intent detection
- Entity extraction
- Multi-turn conversation
- Context management
```

### Phase 3: TTS & Full Loop (Week 7-9)
```bash
- ElevenLabs integration
- Natural Arabic voices
- End-to-end voice loop
```

### Phase 4: Mobile Integration (Week 10-12)
```bash
- React Native Voice
- Real-time streaming
- UI/UX Ù„Ù„Ù…Ø­Ø§Ø¯Ø«Ø© Ø§Ù„ØµÙˆØªÙŠØ©
- Testing & optimization
```

---

## 9. Accessibility Features {#accessibility}

### 9.1 Ù„Ù„Ù…ÙƒÙÙˆÙÙŠÙ† ÙˆØ¶Ø¹Ø§Ù Ø§Ù„Ø¨ØµØ±

```typescript
const ACCESSIBILITY_FEATURES = {

  // Screen Reader Integration
  screenReader: {
    enabled: true,
    verbosity: 'detailed',  // ÙˆØµÙ Ù…ÙØµÙ„ Ù„ÙƒÙ„ Ø¹Ù†ØµØ±
    hapticFeedback: true    // Ø§Ù‡ØªØ²Ø§Ø² Ø¹Ù†Ø¯ Ø§Ù„Ø£Ø²Ø±Ø§Ø±
  },

  // Voice-Only Mode
  voiceOnly: {
    enabled: true,
    autoPlay: true,         // ØªØ´ØºÙŠÙ„ Ø§Ù„Ø±Ø¯ÙˆØ¯ ØªÙ„Ù‚Ø§Ø¦ÙŠØ§Ù‹
    skipVisuals: true       // ØªØ®Ø·ÙŠ Ø§Ù„Ø¹Ù†Ø§ØµØ± Ø§Ù„Ù…Ø±Ø¦ÙŠØ©
  },

  // Large Text
  textSize: {
    min: 20,                // Ø­Ø¬Ù… Ø®Ø· ÙƒØ¨ÙŠØ±
    adjustable: true
  }
};
```

### 9.2 Ù„Ù„Ø£Ù…ÙŠÙŠÙ†

```typescript
const ILLITERATE_MODE = {
  // Visual Icons Only
  icons: {
    size: 'large',
    labels: 'voice',        // Ø´Ø±Ø­ ØµÙˆØªÙŠ Ù„Ù„Ø£ÙŠÙ‚ÙˆÙ†Ø§Øª
    confirmation: 'voice'   // ØªØ£ÙƒÙŠØ¯ ØµÙˆØªÙŠ Ù‚Ø¨Ù„ Ø§Ù„Ø¥Ø¬Ø±Ø§Ø¡Ø§Øª
  },

  // Simplified Navigation
  navigation: {
    maxOptions: 4,          // Ø®ÙŠØ§Ø±Ø§Øª Ù…Ø­Ø¯ÙˆØ¯Ø©
    guided: true,           // Ø¥Ø±Ø´Ø§Ø¯ Ø®Ø·ÙˆØ© Ø¨Ø®Ø·ÙˆØ©
    voiceHelp: 'always'     // Ù…Ø³Ø§Ø¹Ø¯Ø© ØµÙˆØªÙŠØ© Ø¯Ø§Ø¦Ù…Ø§Ù‹
  }
};
```

---

**ØªØ§Ø±ÙŠØ® Ø§Ù„Ø¥Ù†Ø´Ø§Ø¡:** Ø¯ÙŠØ³Ù…Ø¨Ø± 2024
**Ø§Ù„Ø¥ØµØ¯Ø§Ø±:** 1.0
**Ø§Ù„Ù…Ø·ÙˆØ±:** Xchange Egypt Platform Team
